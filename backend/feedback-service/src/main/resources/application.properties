spring.application.name=feedback-service
server.port=8083

spring.datasource.url=jdbc:postgresql://localhost:5432/lms_db?currentSchema=feedback_schema
spring.datasource.username=postgres
spring.datasource.password=ksdk1357@A
spring.datasource.driver-class-name=org.postgresql.Driver

# JPA/Hibernate Configuration
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=true
#spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.properties.hibernate.default_schema=feedback_schema

# Run schema-init.sql on startup
spring.sql.init.mode=always
spring.sql.init.schema-locations=classpath:schema-init.sql

# Large Object Support
spring.jpa.properties.hibernate.jdbc.lob.non_contextual_creation=true

# WebSocket Configuration
spring.websocket.allowed-origins=http://localhost:3000,http://localhost:3001

## Redis Configuration
#spring.data.redis.host=localhost
#spring.data.redis.port=6379
#spring.data.redis.timeout=60000
#spring.cache.type=redis
#spring.cache.redis.time-to-live=604800000
#
## Ollama Configuration (Open-Source LLM)
#ollama.base-url=http://localhost:11434
#ollama.model=llama3.2
#ollama.timeout=120
#ollama.temperature=0.7
#ollama.max-tokens=2000
#
## Alternative: LocalAI Configuration (if using LocalAI instead)
#localai.base-url=http://localhost:8080
#localai.model=ggml-gpt4all-j
#localai.enabled=false
#
## AI Feedback Configuration
#ai.feedback.enabled=true
#ai.feedback.provider=ollama
#ai.feedback.max-retries=3
#ai.feedback.cache-enabled=true
#ai.feedback.cache-ttl-days=7
#ai.feedback.fallback-to-simple=true
#
## External Service URLs
#submission.service.url=http://localhost:8081
#version.control.service.url=http://localhost:8082
#
## Async Configuration
#spring.task.execution.pool.core-size=5
#spring.task.execution.pool.max-size=10
#spring.task.execution.pool.queue-capacity=100
#
## Logging Configuration
#logging.level.com.smartlms.feedback=DEBUG
#logging.level.org.springframework.web=INFO
#logging.level.org.hibernate.SQL=DEBUG

# Redis Configuration (Optional)
spring.data.redis.host=localhost
spring.data.redis.port=6379
spring.data.redis.timeout=60000

# Hugging Face Configuration
huggingface.api-key=YOUR_HF_TOKEN_HERE
huggingface.api-url=https://api-inference.huggingface.co/models
huggingface.model=mistralai/Mistral-7B-Instruct-v0.2
huggingface.timeout=120
huggingface.max-tokens=2000

# AI Provider (huggingface or ollama)
ai.provider=huggingface

# AI Feedback Configuration
ai.feedback.cache-enabled=true
ai.feedback.cache-ttl-days=7
ai.feedback.async-enabled=true
ai.feedback.max-concurrent-requests=5

# Logging
logging.level.root=INFO
logging.level.com.smartlms.feedback=DEBUG
logging.level.org.springframework.web=DEBUG
logging.level.org.hibernate.SQL=DEBUG

# Actuator
management.endpoints.web.exposure.include=health,info,metrics
management.endpoint.health.show-details=always